{"ast":null,"code":"// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nimport { __rest } from \"tslib\";\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\nimport { isTokenCredential } from \"@azure/core-auth\";\nimport { getAudioTranscription, getAudioTranslation, getImages, streamChatCompletions, streamCompletions } from \"./api/index.js\";\nimport { getChatCompletions, getCompletions, getEmbeddings } from \"./api/client/openAIClient/index.js\";\nimport { createOpenAI } from \"./api/index.js\";\nimport { nonAzurePolicy } from \"./api/policies/nonAzure.js\";\n/**\n * A client for interacting with Azure OpenAI.\n *\n * The client needs the endpoint of an OpenAI resource and an authentication\n * method such as an API key or token. The API key and endpoint can be found in\n * the OpenAI resource page. They will be located in the resource's Keys and Endpoint page.\n *\n * ### Examples for authentication:\n *\n * #### API Key\n *\n * ```js\n * import { OpenAIClient } from \"@azure/openai\";\n * import { AzureKeyCredential } from \"@azure/core-auth\";\n *\n * const endpoint = \"<azure endpoint>\";\n * const credential = new AzureKeyCredential(\"<api key>\");\n *\n * const client = new OpenAIClient(endpoint, credential);\n * ```\n *\n * #### Azure Active Directory\n *\n * ```js\n * import { OpenAIClient } from \"@azure/openai\";\n * import { DefaultAzureCredential } from \"@azure/identity\";\n *\n * const endpoint = \"<azure endpoint>\";\n * const credential = new DefaultAzureCredential();\n *\n * const client = new OpenAIClient(endpoint, credential);\n * ```\n */\nexport class OpenAIClient {\n  constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {\n    var _a, _b;\n    this._isAzure = false;\n    let opts;\n    let endpoint;\n    let cred;\n    if (isCred(credOrOptions)) {\n      endpoint = endpointOrOpenAiKey;\n      cred = credOrOptions;\n      opts = options;\n      this._isAzure = true;\n    } else {\n      endpoint = createOpenAIEndpoint(1);\n      cred = endpointOrOpenAiKey;\n      const {\n          credentials\n        } = credOrOptions,\n        restOpts = __rest(credOrOptions, [\"credentials\"]);\n      opts = Object.assign({\n        credentials: {\n          apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : \"Authorization\",\n          scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes\n        }\n      }, restOpts);\n    }\n    this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), this._isAzure ? {} : {\n      additionalPolicies: [...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []), {\n        position: \"perCall\",\n        policy: nonAzurePolicy()\n      }]\n    }));\n  }\n  /**\n   * Returns textual completions as configured for a given prompt.\n   * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this completions request.\n   * @returns The completions for the given prompt.\n   */\n  getCompletions(deploymentName, prompt, options = {\n    requestOptions: {}\n  }) {\n    this.setModel(deploymentName, options);\n    return getCompletions(this._client, deploymentName, prompt, options);\n  }\n  /**\n   * Lists the completions tokens as they become available for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The completions options for this completions request.\n   * @returns An asynchronous iterable of completions tokens.\n   */\n  streamCompletions(deploymentName, prompt, options = {}) {\n    this.setModel(deploymentName, options);\n    return streamCompletions(this._client, deploymentName, prompt, options);\n  }\n  /**\n   * Return the computed embeddings for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param input - The prompt to use for this request.\n   * @param options - The embeddings options for this embeddings request.\n   * @returns The embeddings for the given prompt.\n   */\n  getEmbeddings(deploymentName, input, options = {\n    requestOptions: {}\n  }) {\n    this.setModel(deploymentName, options);\n    return getEmbeddings(this._client, deploymentName, Object.assign({\n      input\n    }, options), options);\n  }\n  /**\n   * Get chat completions for provided chat context messages.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this completions request.\n   * @returns The chat completions for the given chat context messages.\n   */\n  getChatCompletions(deploymentName, messages, options = {\n    requestOptions: {}\n  }) {\n    this.setModel(deploymentName, options);\n    return getChatCompletions(this._client, deploymentName, messages, options);\n  }\n  /**\n   * Lists the chat completions tokens as they become available for a chat context.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this chat completions request.\n   * @returns An asynchronous iterable of chat completions tokens.\n   */\n  streamChatCompletions(deploymentName, messages, options = {\n    requestOptions: {}\n  }) {\n    this.setModel(deploymentName, options);\n    return streamChatCompletions(this._client, deploymentName, messages, options);\n  }\n  /**\n   * Starts the generation of a batch of images from a text caption\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this image request.\n   * @returns The image generation response (containing url or base64 data).\n   */\n  getImages(deploymentName, prompt, options = {\n    requestOptions: {}\n  }) {\n    this.setModel(deploymentName, options);\n    return getImages(this._client, deploymentName, prompt, options);\n  }\n  async getAudioTranscription(deploymentName, fileContent, formatOrOptions, inputOptions) {\n    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : typeof formatOrOptions === \"string\" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {};\n    const response_format = typeof formatOrOptions === \"string\" ? formatOrOptions : undefined;\n    this.setModel(deploymentName, options);\n    if (response_format === undefined) {\n      return getAudioTranscription(this._client, deploymentName, fileContent, options);\n    }\n    return getAudioTranscription(this._client, deploymentName, fileContent, response_format, options);\n  }\n  async getAudioTranslation(deploymentName, fileContent, formatOrOptions, inputOptions) {\n    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : typeof formatOrOptions === \"string\" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {};\n    const response_format = typeof formatOrOptions === \"string\" ? formatOrOptions : undefined;\n    this.setModel(deploymentName, options);\n    if (response_format === undefined) {\n      return getAudioTranslation(this._client, deploymentName, fileContent, options);\n    }\n    return getAudioTranslation(this._client, deploymentName, fileContent, response_format, options);\n  }\n  setModel(model, options) {\n    if (!this._isAzure) {\n      options.model = model;\n    }\n  }\n}\nfunction createOpenAIEndpoint(version) {\n  return `https://api.openai.com/v${version}`;\n}\nfunction isCred(cred) {\n  return isTokenCredential(cred) || cred.key !== undefined;\n}","map":{"version":3,"names":["isTokenCredential","getAudioTranscription","getAudioTranslation","getImages","streamChatCompletions","streamCompletions","getChatCompletions","getCompletions","getEmbeddings","createOpenAI","nonAzurePolicy","OpenAIClient","constructor","endpointOrOpenAiKey","credOrOptions","options","_isAzure","opts","endpoint","cred","isCred","createOpenAIEndpoint","credentials","restOpts","__rest","Object","assign","apiKeyHeaderName","_a","scopes","_client","additionalPolicies","_b","position","policy","deploymentName","prompt","requestOptions","setModel","input","messages","fileContent","formatOrOptions","inputOptions","response_format","undefined","model","version","key"],"sources":["/workspaces/codespaces-blank/jupyter_react/node_modules/@azure/openai/src/OpenAIClient.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { KeyCredential, TokenCredential, isTokenCredential } from \"@azure/core-auth\";\nimport {\n  getAudioTranscription,\n  getAudioTranslation,\n  getImages,\n  streamChatCompletions,\n  streamCompletions,\n} from \"./api/index.js\";\nimport {\n  getChatCompletions,\n  getCompletions,\n  getEmbeddings,\n} from \"./api/client/openAIClient/index.js\";\nimport { OpenAIClientOptions, OpenAIContext, createOpenAI } from \"./api/index.js\";\nimport { nonAzurePolicy } from \"./api/policies/nonAzure.js\";\nimport {\n  AudioResult,\n  AudioResultFormat,\n  AudioResultSimpleJson,\n  GetAudioTranscriptionOptions,\n  GetAudioTranslationOptions,\n} from \"./models/audio.js\";\nimport {\n  GetImagesOptions,\n  GetCompletionsOptions,\n  GetEmbeddingsOptions,\n  GetChatCompletionsOptions,\n} from \"./models/options.js\";\nimport {\n  ChatCompletions,\n  ChatRequestMessage,\n  Completions,\n  Embeddings,\n  EventStream,\n  ImageGenerations,\n} from \"./models/models.js\";\n\nexport { OpenAIClientOptions } from \"./api/OpenAIContext.js\";\n\n/**\n * A client for interacting with Azure OpenAI.\n *\n * The client needs the endpoint of an OpenAI resource and an authentication\n * method such as an API key or token. The API key and endpoint can be found in\n * the OpenAI resource page. They will be located in the resource's Keys and Endpoint page.\n *\n * ### Examples for authentication:\n *\n * #### API Key\n *\n * ```js\n * import { OpenAIClient } from \"@azure/openai\";\n * import { AzureKeyCredential } from \"@azure/core-auth\";\n *\n * const endpoint = \"<azure endpoint>\";\n * const credential = new AzureKeyCredential(\"<api key>\");\n *\n * const client = new OpenAIClient(endpoint, credential);\n * ```\n *\n * #### Azure Active Directory\n *\n * ```js\n * import { OpenAIClient } from \"@azure/openai\";\n * import { DefaultAzureCredential } from \"@azure/identity\";\n *\n * const endpoint = \"<azure endpoint>\";\n * const credential = new DefaultAzureCredential();\n *\n * const client = new OpenAIClient(endpoint, credential);\n * ```\n */\nexport class OpenAIClient {\n  private _client: OpenAIContext;\n  private _isAzure = false;\n\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A key credential used to authenticate to an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   This constructor initializes an OpenAIClient object that can only be used with Azure OpenAI resources.\n   *   To use OpenAIClient with a non-Azure OpenAI inference endpoint, use a constructor that accepts a non-Azure OpenAI API key instead.\n   */\n  constructor(endpoint: string, credential: KeyCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A token credential used to authenticate with an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   */\n  constructor(endpoint: string, credential: TokenCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with the non-Azure OpenAI endpoint.\n   * @param openAiApiKey - The API key to use when connecting to the non-Azure OpenAI endpoint.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   OpenAIClient objects initialized with this constructor can only be used with the non-Azure OpenAI inference endpoint.\n   *   To use OpenAIClient with an Azure OpenAI resource, use a constructor that accepts a resource URI and Azure authentication credential instead.\n   */\n  constructor(openAiApiKey: KeyCredential, options?: OpenAIClientOptions);\n  constructor(\n    endpointOrOpenAiKey: string | KeyCredential,\n    credOrOptions: KeyCredential | TokenCredential | OpenAIClientOptions = {},\n    options: OpenAIClientOptions = {},\n  ) {\n    let opts: OpenAIClientOptions;\n    let endpoint: string;\n    let cred: KeyCredential | TokenCredential;\n    if (isCred(credOrOptions)) {\n      endpoint = endpointOrOpenAiKey as string;\n      cred = credOrOptions;\n      opts = options;\n      this._isAzure = true;\n    } else {\n      endpoint = createOpenAIEndpoint(1);\n      cred = endpointOrOpenAiKey as KeyCredential;\n      const { credentials, ...restOpts } = credOrOptions;\n      opts = {\n        credentials: {\n          apiKeyHeaderName: credentials?.apiKeyHeaderName ?? \"Authorization\",\n          scopes: credentials?.scopes,\n        },\n        ...restOpts,\n      };\n    }\n\n    this._client = createOpenAI(endpoint, cred, {\n      ...opts,\n      ...(this._isAzure\n        ? {}\n        : {\n            additionalPolicies: [\n              ...(opts.additionalPolicies ?? []),\n              {\n                position: \"perCall\",\n                policy: nonAzurePolicy(),\n              },\n            ],\n          }),\n    });\n  }\n\n  /**\n   * Returns textual completions as configured for a given prompt.\n   * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this completions request.\n   * @returns The completions for the given prompt.\n   */\n  getCompletions(\n    deploymentName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = { requestOptions: {} },\n  ): Promise<Completions> {\n    this.setModel(deploymentName, options);\n    return getCompletions(this._client, deploymentName, prompt, options);\n  }\n\n  /**\n   * Lists the completions tokens as they become available for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The completions options for this completions request.\n   * @returns An asynchronous iterable of completions tokens.\n   */\n  streamCompletions(\n    deploymentName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = {},\n  ): Promise<EventStream<Omit<Completions, \"usage\">>> {\n    this.setModel(deploymentName, options);\n    return streamCompletions(this._client, deploymentName, prompt, options);\n  }\n\n  /**\n   * Return the computed embeddings for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param input - The prompt to use for this request.\n   * @param options - The embeddings options for this embeddings request.\n   * @returns The embeddings for the given prompt.\n   */\n  getEmbeddings(\n    deploymentName: string,\n    input: string[],\n    options: GetEmbeddingsOptions = { requestOptions: {} },\n  ): Promise<Embeddings> {\n    this.setModel(deploymentName, options);\n    return getEmbeddings(this._client, deploymentName, { input, ...options }, options);\n  }\n\n  /**\n   * Get chat completions for provided chat context messages.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this completions request.\n   * @returns The chat completions for the given chat context messages.\n   */\n  getChatCompletions(\n    deploymentName: string,\n    messages: ChatRequestMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} },\n  ): Promise<ChatCompletions> {\n    this.setModel(deploymentName, options);\n    return getChatCompletions(this._client, deploymentName, messages, options);\n  }\n\n  /**\n   * Lists the chat completions tokens as they become available for a chat context.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this chat completions request.\n   * @returns An asynchronous iterable of chat completions tokens.\n   */\n  streamChatCompletions(\n    deploymentName: string,\n    messages: ChatRequestMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} },\n  ): Promise<EventStream<ChatCompletions>> {\n    this.setModel(deploymentName, options);\n    return streamChatCompletions(this._client, deploymentName, messages, options);\n  }\n\n  /**\n   * Starts the generation of a batch of images from a text caption\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this image request.\n   * @returns The image generation response (containing url or base64 data).\n   */\n  getImages(\n    deploymentName: string,\n    prompt: string,\n    options: GetImagesOptions = { requestOptions: {} },\n  ): Promise<ImageGenerations> {\n    this.setModel(deploymentName, options);\n    return getImages(this._client, deploymentName, prompt, options);\n  }\n\n  /**\n   * Returns the transcription of an audio file in a simple JSON format.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param fileContent - The content of the audio file to transcribe.\n   * @param options - The options for this audio transcription request.\n   * @returns The audio transcription result in a simple JSON format.\n   */\n  async getAudioTranscription(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    options?: GetAudioTranscriptionOptions,\n  ): Promise<AudioResultSimpleJson>;\n  /**\n   * Returns the transcription of an audio file.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param fileContent - The content of the audio file to transcribe.\n   * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.\n   * @param options - The options for this audio transcription request.\n   * @returns The audio transcription result in a format of your choice.\n   */\n  async getAudioTranscription<Format extends AudioResultFormat>(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    format: Format,\n    options?: GetAudioTranscriptionOptions,\n  ): Promise<AudioResult<Format>>;\n  async getAudioTranscription<Format extends AudioResultFormat>(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    formatOrOptions?: Format | GetAudioTranscriptionOptions,\n    inputOptions?: GetAudioTranscriptionOptions,\n  ): Promise<AudioResult<Format>> {\n    const options =\n      inputOptions ?? (typeof formatOrOptions === \"string\" ? {} : formatOrOptions ?? {});\n    const response_format = typeof formatOrOptions === \"string\" ? formatOrOptions : undefined;\n    this.setModel(deploymentName, options);\n    if (response_format === undefined) {\n      return getAudioTranscription(this._client, deploymentName, fileContent, options) as Promise<\n        AudioResult<Format>\n      >;\n    }\n\n    return getAudioTranscription(\n      this._client,\n      deploymentName,\n      fileContent,\n      response_format,\n      options,\n    );\n  }\n\n  /**\n   * Returns the translation of an audio file.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param fileContent - The content of the audio file to translate.\n   * @param options - The options for this audio translation request.\n   * @returns The audio translation result.\n   */\n  async getAudioTranslation(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    options?: GetAudioTranslationOptions,\n  ): Promise<AudioResultSimpleJson>;\n  /**\n   * Returns the translation of an audio file.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param fileContent - The content of the audio file to translate.\n   * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.\n   * @param options - The options for this audio translation request.\n   * @returns The audio translation result.\n   */\n  async getAudioTranslation<Format extends AudioResultFormat>(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    format: Format,\n    options?: GetAudioTranslationOptions,\n  ): Promise<AudioResult<Format>>;\n  async getAudioTranslation<Format extends AudioResultFormat>(\n    deploymentName: string,\n    fileContent: Uint8Array,\n    formatOrOptions?: Format | GetAudioTranslationOptions,\n    inputOptions?: GetAudioTranslationOptions,\n  ): Promise<AudioResult<Format>> {\n    const options =\n      inputOptions ?? (typeof formatOrOptions === \"string\" ? {} : formatOrOptions ?? {});\n    const response_format = typeof formatOrOptions === \"string\" ? formatOrOptions : undefined;\n    this.setModel(deploymentName, options);\n    if (response_format === undefined) {\n      return getAudioTranslation(this._client, deploymentName, fileContent, options) as Promise<\n        AudioResult<Format>\n      >;\n    }\n\n    return getAudioTranslation(this._client, deploymentName, fileContent, response_format, options);\n  }\n\n  private setModel(model: string, options: Record<string, any>): void {\n    if (!this._isAzure) {\n      options.model = model;\n    }\n  }\n}\n\nfunction createOpenAIEndpoint(version: number): string {\n  return `https://api.openai.com/v${version}`;\n}\n\nfunction isCred(cred: Record<string, any>): cred is TokenCredential | KeyCredential {\n  return isTokenCredential(cred) || cred.key !== undefined;\n}\n"],"mappings":"AAAA;AACA;;AAEA;;;;;;;AAQA,SAAyCA,iBAAiB,QAAQ,kBAAkB;AACpF,SACEC,qBAAqB,EACrBC,mBAAmB,EACnBC,SAAS,EACTC,qBAAqB,EACrBC,iBAAiB,QACZ,gBAAgB;AACvB,SACEC,kBAAkB,EAClBC,cAAc,EACdC,aAAa,QACR,oCAAoC;AAC3C,SAA6CC,YAAY,QAAQ,gBAAgB;AACjF,SAASC,cAAc,QAAQ,4BAA4B;AAyB3D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiCA,OAAM,MAAOC,YAAY;EAgCvBC,YACEC,mBAA2C,EAC3CC,aAAA,GAAuE,EAAE,EACzEC,OAAA,GAA+B,EAAE;;IAjC3B,KAAAC,QAAQ,GAAG,KAAK;IAmCtB,IAAIC,IAAyB;IAC7B,IAAIC,QAAgB;IACpB,IAAIC,IAAqC;IACzC,IAAIC,MAAM,CAACN,aAAa,CAAC,EAAE;MACzBI,QAAQ,GAAGL,mBAA6B;MACxCM,IAAI,GAAGL,aAAa;MACpBG,IAAI,GAAGF,OAAO;MACd,IAAI,CAACC,QAAQ,GAAG,IAAI;IACtB,CAAC,MAAM;MACLE,QAAQ,GAAGG,oBAAoB,CAAC,CAAC,CAAC;MAClCF,IAAI,GAAGN,mBAAoC;MAC3C,MAAM;UAAES;QAAW,IAAkBR,aAAa;QAA1BS,QAAQ,GAAAC,MAAA,CAAKV,aAAa,EAA5C,eAA4B,CAAgB;MAClDG,IAAI,GAAAQ,MAAA,CAAAC,MAAA;QACFJ,WAAW,EAAE;UACXK,gBAAgB,EAAE,CAAAC,EAAA,GAAAN,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAEK,gBAAgB,cAAAC,EAAA,cAAAA,EAAA,GAAI,eAAe;UAClEC,MAAM,EAAEP,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAEO;;MACtB,GACEN,QAAQ,CACZ;IACH;IAEA,IAAI,CAACO,OAAO,GAAGrB,YAAY,CAACS,QAAQ,EAAEC,IAAI,EAAAM,MAAA,CAAAC,MAAA,CAAAD,MAAA,CAAAC,MAAA,KACrCT,IAAI,GACH,IAAI,CAACD,QAAQ,GACb,EAAE,GACF;MACEe,kBAAkB,EAAE,CAClB,IAAI,CAAAC,EAAA,GAAAf,IAAI,CAACc,kBAAkB,cAAAC,EAAA,cAAAA,EAAA,GAAI,EAAE,CAAC,EAClC;QACEC,QAAQ,EAAE,SAAS;QACnBC,MAAM,EAAExB,cAAc;OACvB;KAEH,EACN;EACJ;EAEA;;;;;;;EAOAH,cAAcA,CACZ4B,cAAsB,EACtBC,MAAgB,EAChBrB,OAAA,GAAiC;IAAEsB,cAAc,EAAE;EAAE,CAAE;IAEvD,IAAI,CAACC,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOR,cAAc,CAAC,IAAI,CAACuB,OAAO,EAAEK,cAAc,EAAEC,MAAM,EAAErB,OAAO,CAAC;EACtE;EAEA;;;;;;;EAOAV,iBAAiBA,CACf8B,cAAsB,EACtBC,MAAgB,EAChBrB,OAAA,GAAiC,EAAE;IAEnC,IAAI,CAACuB,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOV,iBAAiB,CAAC,IAAI,CAACyB,OAAO,EAAEK,cAAc,EAAEC,MAAM,EAAErB,OAAO,CAAC;EACzE;EAEA;;;;;;;EAOAP,aAAaA,CACX2B,cAAsB,EACtBI,KAAe,EACfxB,OAAA,GAAgC;IAAEsB,cAAc,EAAE;EAAE,CAAE;IAEtD,IAAI,CAACC,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOP,aAAa,CAAC,IAAI,CAACsB,OAAO,EAAEK,cAAc,EAAAV,MAAA,CAAAC,MAAA;MAAIa;IAAK,GAAKxB,OAAO,GAAIA,OAAO,CAAC;EACpF;EAEA;;;;;;;EAOAT,kBAAkBA,CAChB6B,cAAsB,EACtBK,QAA8B,EAC9BzB,OAAA,GAAqC;IAAEsB,cAAc,EAAE;EAAE,CAAE;IAE3D,IAAI,CAACC,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOT,kBAAkB,CAAC,IAAI,CAACwB,OAAO,EAAEK,cAAc,EAAEK,QAAQ,EAAEzB,OAAO,CAAC;EAC5E;EAEA;;;;;;;EAOAX,qBAAqBA,CACnB+B,cAAsB,EACtBK,QAA8B,EAC9BzB,OAAA,GAAqC;IAAEsB,cAAc,EAAE;EAAE,CAAE;IAE3D,IAAI,CAACC,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOX,qBAAqB,CAAC,IAAI,CAAC0B,OAAO,EAAEK,cAAc,EAAEK,QAAQ,EAAEzB,OAAO,CAAC;EAC/E;EAEA;;;;;;;EAOAZ,SAASA,CACPgC,cAAsB,EACtBC,MAAc,EACdrB,OAAA,GAA4B;IAAEsB,cAAc,EAAE;EAAE,CAAE;IAElD,IAAI,CAACC,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,OAAOZ,SAAS,CAAC,IAAI,CAAC2B,OAAO,EAAEK,cAAc,EAAEC,MAAM,EAAErB,OAAO,CAAC;EACjE;EA4BA,MAAMd,qBAAqBA,CACzBkC,cAAsB,EACtBM,WAAuB,EACvBC,eAAuD,EACvDC,YAA2C;IAE3C,MAAM5B,OAAO,GACX4B,YAAY,aAAZA,YAAY,cAAZA,YAAY,GAAK,OAAOD,eAAe,KAAK,QAAQ,GAAG,EAAE,GAAGA,eAAe,aAAfA,eAAe,cAAfA,eAAe,GAAI,EAAG;IACpF,MAAME,eAAe,GAAG,OAAOF,eAAe,KAAK,QAAQ,GAAGA,eAAe,GAAGG,SAAS;IACzF,IAAI,CAACP,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,IAAI6B,eAAe,KAAKC,SAAS,EAAE;MACjC,OAAO5C,qBAAqB,CAAC,IAAI,CAAC6B,OAAO,EAAEK,cAAc,EAAEM,WAAW,EAAE1B,OAAO,CAE9E;IACH;IAEA,OAAOd,qBAAqB,CAC1B,IAAI,CAAC6B,OAAO,EACZK,cAAc,EACdM,WAAW,EACXG,eAAe,EACf7B,OAAO,CACR;EACH;EA4BA,MAAMb,mBAAmBA,CACvBiC,cAAsB,EACtBM,WAAuB,EACvBC,eAAqD,EACrDC,YAAyC;IAEzC,MAAM5B,OAAO,GACX4B,YAAY,aAAZA,YAAY,cAAZA,YAAY,GAAK,OAAOD,eAAe,KAAK,QAAQ,GAAG,EAAE,GAAGA,eAAe,aAAfA,eAAe,cAAfA,eAAe,GAAI,EAAG;IACpF,MAAME,eAAe,GAAG,OAAOF,eAAe,KAAK,QAAQ,GAAGA,eAAe,GAAGG,SAAS;IACzF,IAAI,CAACP,QAAQ,CAACH,cAAc,EAAEpB,OAAO,CAAC;IACtC,IAAI6B,eAAe,KAAKC,SAAS,EAAE;MACjC,OAAO3C,mBAAmB,CAAC,IAAI,CAAC4B,OAAO,EAAEK,cAAc,EAAEM,WAAW,EAAE1B,OAAO,CAE5E;IACH;IAEA,OAAOb,mBAAmB,CAAC,IAAI,CAAC4B,OAAO,EAAEK,cAAc,EAAEM,WAAW,EAAEG,eAAe,EAAE7B,OAAO,CAAC;EACjG;EAEQuB,QAAQA,CAACQ,KAAa,EAAE/B,OAA4B;IAC1D,IAAI,CAAC,IAAI,CAACC,QAAQ,EAAE;MAClBD,OAAO,CAAC+B,KAAK,GAAGA,KAAK;IACvB;EACF;;AAGF,SAASzB,oBAAoBA,CAAC0B,OAAe;EAC3C,OAAO,2BAA2BA,OAAO,EAAE;AAC7C;AAEA,SAAS3B,MAAMA,CAACD,IAAyB;EACvC,OAAOnB,iBAAiB,CAACmB,IAAI,CAAC,IAAIA,IAAI,CAAC6B,GAAG,KAAKH,SAAS;AAC1D","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}